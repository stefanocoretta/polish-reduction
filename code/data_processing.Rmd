---
title: "Data processing"
output: 
  pdf_document: 
    number_sections: yes
    latex_engine: xelatex
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(tidyverse)
library(rticulate)
```

# Process spline data

```{r midpoint-wide}
col_names <- c(
  "speaker",
  "time_ann",
  "time_rec",
  "date",
  "dur",
  "prompt",
  "label"
)

items_data <- read_csv("./data/raw/items_data.csv")

# Note: Extra empty column in PL02, 3, 4, 7, 8 has been manually removed
midpoint_wide <- list.files(
  path = "./data/raw/splines/",
  pattern = "*.txt",
  full.names = TRUE
) %>%
  read_aaa(., column_names = col_names, format = "wide") %>%
  # Create item column from prompt
  mutate(
    # Extract second word in prompt
    item = word(prompt, 2),
    # Remove single quotes
    item = str_replace_all(item, "'", ""),
    # Fix replacement character
    item = str_replace(item, "nowotw�r", "nowotwor"),
  ) %>%
  # Create block column based on rec date
  unite("sep", speaker, item, label, remove = FALSE) %>%
  group_by(sep) %>%
  mutate(
    block = as.numeric(as.factor(date))
  ) %>%
  # Create rate column based on block column
  mutate(
    rate = case_when(
      block %in% c(1, 2) ~ "slow",
      block %in% c(3, 4) ~ "normal",
      block %in% c(5, 6) ~ "fast"
    )
  ) %>%
  # Join tibble with items_data
  left_join(y = items_data) %>%
  ungroup() %>%
  select(-sep)
```

```{r midpoint-long}
# Make long dataset with spline data
midpoint_long <- midpoint_wide %>%
  pivot_longer(
    matches("[XY]_\\d{1,2}"),
  ) %>%
  separate(name, into = c("coord", "fan_line")) %>%
  pivot_wider(
    names_from = "coord",
    values_from = "value"
  )
```

```{r save-spline-data}
saveRDS(midpoint_wide, file = "./data/derived/midpoint_wide.rds")
saveRDS(midpoint_long, file = "./data/derived/midpoint_long.rds")
```

# Process formant data

```{r formant-data}
formant_data <- read_csv("./data/raw/measurements.csv") %>%
  filter(!(item %in% c("mimo", "mimoza", "zima", "zimami"))) %>%
  bind_rows(read_csv("./data/raw/i.csv", na = "--undefined--")) %>%
  mutate(
    # Fix replacement character
    item = str_replace(item, "nowotwÛr", "nowotwor"),
    start = round(start, 4)
  )

formant_data[formant_data$item == "ma" & formant_data$start == 453.3759,]$item <- "bywa"
formant_data[formant_data$item == "ma" & formant_data$start == 470.9234,]$item <- "zywo"
formant_data[formant_data$item == "ma" & formant_data$start == 473.6989,]$item <- "kuma"

# Substitute outlier measurements with hand-corrected measurements at midpoint
outliers <- read_csv("./data/raw/outliers.csv")
formant_data <- anti_join(formant_data, outliers, by = c("speaker", "item", "start", "tp")) %>%
  bind_rows(outliers)

formant_data <- formant_data %>%
  # Create block column based on rec date
  unite("sep", speaker, item, label, remove = FALSE) %>%
  group_by(sep) %>%
  mutate(
    block = as.numeric(as.factor(start))
  ) %>%
  # Create rate column based on block column
  mutate(
    rate = case_when(
      block %in% c(1, 2) ~ "slow",
      block %in% c(3, 4) ~ "normal",
      block %in% c(5, 6) ~ "fast"
    )
  ) %>%
  mutate(
    duration = duration * 1000
  ) %>%
  # Join tibble with items_data
  left_join(y = items_data) %>%
  select(-sep)

# Select only mid-point measurements
formant_midpoint <- formant_data %>%
  filter(tp == 5) %>%
  ungroup() %>%
  group_by(speaker) %>%
  mutate(
    f1.z = scale(f1),
    f2.z = scale(f2)
  ) %>%
  ungroup()
```

```{r save-formant-data}
saveRDS(formant_data, file = "./data/derived/formant_data.rds")
saveRDS(formant_midpoint, file = "./data/derived/formant_midpoint.rds")
```

# Apply PCA and rotation

This function takes a wide spline dataset as input, where spline data are in Cartesian coordinates named X_1:Y_42. This function drops fan lines with missing data, and performs a PCA on the rest of the data.

```{r tongue-contour-pca}
tongue_contour_pca <- function(df) {
  # Identify columns without missing values
  columns <- df %>%
    select(X_1:Y_42) %>%
    select_if(~ !any(is.na(.)))
  
  # Select columns with no missing values
  pca.input <-  df %>%
    select(one_of(colnames(columns)))
  
  ## Run PCA
  tongue.pca <- prcomp(pca.input,
                       center = TRUE,
                       scale. = TRUE) 
  
  # Add PCs to data set
  df$PC1 <- predict(tongue.pca, df)[,1]
  df$PC2 <- predict(tongue.pca, df)[,2]
  # Include proportion of variance explained for each PC
  df$PC1_var <- as.numeric(summary(tongue.pca)$importance[2,][1])
  df$PC2_var <- as.numeric(summary(tongue.pca)$importance[2,][2])
  return(df)
}
```

This function applies linear regression performing formants, based on PC1 and PC2.
Predicted formant values are added to the data (comp1 and comp2).

```{r rotate-PCs}
rotate_PCs <- function(df) {
  f1.lm <- lm(f1.z ~ PC1 + PC2, data = df)
  df$comp1 <- predict(f1.lm, df)

  f2.lm <- lm(f2.z ~ PC1 + PC2, data = df)
  df$comp2 = predict(f2.lm, df)
  return(df)
}
```

Run PCA for each speaker in the dataset.

```{r pca-out}
pca_output <- midpoint_wide %>%
  filter(label == 'V1') %>%
  group_by(speaker) %>%
  do(tongue_contour_pca(.)) %>%
  ungroup()
```

```{r midpoint-rotated}
midpoint_rotated <- pca_output %>%
  select(speaker, item, block, PC1, PC2, PC1_var, PC2_var) %>%
  left_join(formant_midpoint %>% select(speaker, item, block, f1.z, f2.z)) %>%
  group_by(speaker) %>%
  do(rotate_PCs(.)) %>%
  ungroup() %>%
  select(speaker:PC2_var, comp1, comp2) %>%
  left_join(formant_midpoint) %>%
  select(-sep) %>%
  rename(z1 = "comp1", z2 = "comp2")
```

```{r save-midpoint-rotated}
saveRDS(midpoint_rotated, file = "./data/derived/midpoint_rotated.rds")
```

